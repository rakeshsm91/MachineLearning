{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Homework Solutions\n",
    "***\n",
    "**Name**: $<$Rakesh Shivanand Margoor$>$ \n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Friday January 26th**. Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. Your solutions to analysis questions should be done in Markdown directly below the associated question.  Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**.  For a refresher on the course **Collaboration Policy** click [here](https://github.com/chrisketelsen/CSCI5622-Machine-Learning/blob/master/resources/syllabus.md#collaboration-policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "***\n",
    "\n",
    "\n",
    "In this homework you'll implement a K-Nearest Neighbor framework to take an image of a handwritten digit and predict which digit it corresponds to.  \n",
    "\n",
    "<br>\n",
    "\n",
    "![Samples of Handwritten Digits](wide_mnist.png \"MNIST Digits\")\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "This homework is designed to be pretty easy. If you're spending a ton of time on this assignment, then you are either:\n",
    "\n",
    "- not prepared to take this course (i.e., if you're struggling with Python)\n",
    "- seriously over-thinking the assignment\n",
    "- trying to implement too much of KNN from scratch\n",
    "\n",
    "\n",
    "Most of this assignment will be done by calling libraries that are already implemented for you. If you are implementing $n$-dimensional search or your own distance metrics, you are generating extra work for yourself and making yourself vulnerable to errors. \n",
    "\n",
    "Here are the rules: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import collections\n",
    "from collections import Counter\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5 points] Problem 1\n",
    "***\n",
    "\n",
    "The class below will load and store the MNIST data.  Load the data and then report: \n",
    "- The number of examples in the training set \n",
    "- The number of examples in the test set \n",
    "- The number of pixels in each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Numbers:\n",
    "    \"\"\"\n",
    "    Class to store MNIST data\n",
    "    \"\"\"\n",
    "    def __init__(self, location):\n",
    "\n",
    "        import pickle, gzip\n",
    "\n",
    "        # load data from file \n",
    "        f = gzip.open(location, 'rb')\n",
    "        train_set, valid_set, test_set = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "        # store for use later  \n",
    "        self.train_x, self.train_y = train_set\n",
    "        self.test_x, self.test_y = valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of examples in the training set =  50000\n",
      "The number of examples in the test set =  10000\n",
      "The number of pixels in each image = 784\n"
     ]
    }
   ],
   "source": [
    "data = Numbers(\"../data/mnist.pklz\")\n",
    "print(\"The number of examples in the training set = \", len(data.train_y))\n",
    "print(\"The number of examples in the test set = \", len(data.test_x))\n",
    "print(\"The number of pixels in each image =\", len(data.test_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [30 points] Problem 2\n",
    "***\n",
    "\n",
    "The class below will perform K-Nearest Neighbor classification on our handwritten digit data. Your tasks are as follows:   \n",
    "\n",
    "1. Modify the `label_counts` function to return a dictionary of frequencies corresponding to each label in the training set. \n",
    "1. Modify the `majority` function so that it returns the _label_ that appears most frequently in the $K$-nearest neighbors of the query point.  In the case that the maximum frequency occurs for two or more labels, return the one that appears most frequently in the entire training set. In the case that there is still a tie, break the tie in any way that you choose. \n",
    "1. Modify the `classify` function so that it finds the _indices_ of the $K$ closest training examples to the query point and then calls the `majority` function to return the predicted label. Almost all of the heavy lifting here will be done by the BallTree object from `sklearn.neighbors`, so you'll want to start out by reading the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html).  \n",
    "1. Modify the `confusion_matrix` function to classify examples and record the results in a confusion matrix. You should construct the confusion matrix on your own.  Don't call any additional functions from sklearn to do it for you.\n",
    "\n",
    "The class Knearest also implements an `accuracy` function which you will use in **Problem 3**.  You should not have to modify this function. \n",
    "\n",
    "We've given you unit tests down below based on the simple example worked out in lecture.  At first your code will fail all of them.  Do not move on to **Problem 3** until your code passes all of the unit tests. In addition, passing the unit tests does not guarantee that your implementation is robust and that you'll earn full points on this problem.  You should be designing your own additional tests as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Knearest:\n",
    "    \"\"\"\n",
    "    kNN classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y, k=5):\n",
    "        \"\"\"\n",
    "        Creates a kNN instance\n",
    "\n",
    "        :param x: Training data input\n",
    "        :param y: Training data output\n",
    "        :param k: The number of nearest points to consider in classification\n",
    "        \"\"\"\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "\n",
    "        self._kdtree = BallTree(X)\n",
    "        self._y = y\n",
    "        self._k = k\n",
    "        self._counts = self.label_counts()\n",
    "        \n",
    "    def label_counts(self):\n",
    "        \"\"\"\n",
    "        Given the training labels, return a dictionary d where d[y] is  \n",
    "        the number of times that label y appears in the training set. \n",
    "        \"\"\"\n",
    "        d = collections.Counter(self._y)\n",
    "        return d\n",
    "\n",
    "    def majority(self, neighbor_indices):\n",
    "        \"\"\"\n",
    "        Given the indices of training examples, return the majority label. Break ties \n",
    "        by choosing the tied label that appears most often in the training data. \n",
    "\n",
    "        :param neighbor_indices: The indices of the k nearest neighbors\n",
    "        \"\"\"\n",
    "        assert len(neighbor_indices) == self._k, \"Did not get k neighbor indices\"\n",
    "        \n",
    "        freq_indices = {}\n",
    "        \n",
    "        for index in neighbor_indices:\n",
    "            k = int(self._y[index])\n",
    "            if k in freq_indices:\n",
    "                freq_indices[k] += 1\n",
    "            else:\n",
    "                freq_indices[k] = 1\n",
    "        \n",
    "        max_value = max(freq_indices.values())  \n",
    "        max_labels = [k for k, v in freq_indices.items() if v == max_value]\n",
    "        max_occurence = -1\n",
    "        for label in max_labels:\n",
    "            if max_occurence < self._counts[label]:\n",
    "                choosed_label = label\n",
    "                max_occurence =  self._counts[label]\n",
    "                \n",
    "            \n",
    "        return choosed_label\n",
    "    \n",
    "\n",
    "    def classify(self, example):\n",
    "        \"\"\"\n",
    "        Given an example, return the predicted label. \n",
    "\n",
    "        :param example: A representation of an example in the same\n",
    "        format as a row of the training data\n",
    "        \"\"\"            \n",
    "        dist, ind = self._kdtree.query(example.reshape(-1, len(example)), k=self._k)\n",
    "        return self.majority(ind[0])\n",
    "\n",
    "\n",
    "    def confusion_matrix(self, test_x, test_y):\n",
    "        \"\"\"\n",
    "        Given a matrix of test examples and labels, compute the confusion\n",
    "        matrix for the current classifier.  Should return a 2-dimensional\n",
    "        numpy array of ints, C, where C[ii,jj] is the number of times an \n",
    "        example with true label ii was labeled as jj.\n",
    "\n",
    "        :param test_x: test data \n",
    "        :param test_y: true test labels \n",
    "        \"\"\"\n",
    "        \n",
    "        C = np.zeros((10,10), dtype=int)\n",
    "        for xx, yy in zip(test_x, test_y):\n",
    "            C[xx][yy] += 1 \n",
    "        \n",
    "        return C \n",
    "            \n",
    "    @staticmethod\n",
    "    def accuracy(C):\n",
    "        \"\"\"\n",
    "        Given a confusion matrix C, compute the accuracy of the underlying classifier.\n",
    "        \n",
    "        :param C: a confusion matrix \n",
    "        \"\"\"\n",
    "        \n",
    "        return np.sum(C.diagonal()) / C.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the unit tests.  You don't need to modify them.  Simply execute the cell and observe the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.011s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestKnn(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.x = np.array([[2, 0], [4, 1], [6, 0], [1, 4], [2, 4], [2, 5], [4, 4], [0, 2], [3, 2], [4, 2], [5, 2], [5, 5]])\n",
    "        self.y = np.array([+1, +1, +1, +1, +1, +1, +1, -1, -1, -1, -1, -1])\n",
    "        self.knn = {}\n",
    "        for ii in [1, 2, 3]:\n",
    "            self.knn[ii] = Knearest(self.x, self.y, ii)\n",
    "\n",
    "        self.queries = np.array([[1, 5], [0, 3], [6, 4]])\n",
    "        \n",
    "    def test0(self):\n",
    "        \"\"\"\n",
    "        Test the label counter \n",
    "        \"\"\"\n",
    "        self.assertEqual(self.knn[1]._counts[-1], 5)\n",
    "        self.assertEqual(self.knn[1]._counts[1], 7)\n",
    "\n",
    "    def test1(self):\n",
    "        \"\"\"\n",
    "        Test 1NN\n",
    "        \"\"\"\n",
    "        self.assertEqual(self.knn[1].classify(self.queries[0]),  1)\n",
    "        self.assertEqual(self.knn[1].classify(self.queries[1]), -1)\n",
    "        self.assertEqual(self.knn[1].classify(self.queries[2]), -1)\n",
    "\n",
    "    def test2(self):\n",
    "        \"\"\"\n",
    "        Test 2NN\n",
    "        \"\"\"\n",
    "        self.assertEqual(self.knn[2].classify(self.queries[0]),  1)\n",
    "        self.assertEqual(self.knn[2].classify(self.queries[1]),  1)\n",
    "        self.assertEqual(self.knn[2].classify(self.queries[2]),  1)\n",
    "\n",
    "    def test3(self):\n",
    "        \"\"\"\n",
    "        Test 3NN\n",
    "        \"\"\"\n",
    "        self.assertEqual(self.knn[3].classify(self.queries[0]),  1)\n",
    "        self.assertEqual(self.knn[3].classify(self.queries[1]),  1)\n",
    "        self.assertEqual(self.knn[3].classify(self.queries[2]), -1)\n",
    "        \n",
    "tests = TestKnn()\n",
    "tests_to_run = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [15 points] Problem 3\n",
    "***\n",
    "\n",
    "In this problem you'll explore the performance of the classifier you've written.  A word of advice: don't use the entire training set, especially at first.  We'll be using this dataset again later on with techniques that scale better.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Explore the relationship between the number of training examples and accuracy on the test set. Comment on your findings and support your observations with some kind of graphic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The accuracy increases with increase in the number of training examples. \n",
    "The increment is very high from 100s to 1000s training samples, \n",
    "The accuracy slowly increases from samples above 10000 as most training becomes repetitive i.e the features become redundant.\n",
    "Below graph shows the relationship between training samples and the accuracy obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_samples = [1000, 2000, 3000, 4000,5000, 6000, 7000, 8000, 9000, 10000]\n",
    "accs=[]\n",
    "for samples in training_samples:\n",
    "    obj = Knearest(data.train_x[:samples], data.train_y[:samples])\n",
    "    yout = np.zeros(len(data.test_x),  dtype=int)\n",
    "    for i in range(len(data.test_x)):\n",
    "        yout[i] = obj.classify(data.test_x[i])\n",
    "\n",
    "    C = obj.confusion_matrix(yout,data.test_y)\n",
    "    acc = Knearest.accuracy(C)\n",
    "    accs.append(acc)\n",
    "\n",
    "plot_data = {}\n",
    "for i in range(len(training_samples)):\n",
    "    plot_data[training_samples[i]] = accs[i]\n",
    "\n",
    "plt.bar(np.arange(len(plot_data)), plot_data.values(), align=\"center\", width=0.2, color='g')\n",
    "plt.xticks(range(len(plot_data)), list(plot_data.keys()))\n",
    "plt.xlabel(\"Training samples\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Explore the relationship between the number of nearest neighbors and accuracy on the test set. Comment on your findings and support your observations with some kind of graphic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code plots the accuracy with k value from 1 to 10. A high accuracy is obtained when k is 3 and 5. \n",
    "The variation of accuracy with respect to k is not linear. \n",
    "The accuracy depends on how well the boundaries are formed to classify the nearest k neighbors and hence a linear direct relationship does not exist between k value and the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95130000000000003, 0.93840000000000001, 0.95279999999999998, 0.94969999999999999, 0.95109999999999995, 0.94820000000000004, 0.94750000000000001, 0.94699999999999995, 0.94550000000000001, 0.94450000000000001]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4c03e9e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_samples = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "accs=[]\n",
    "for samples in k_samples:\n",
    "    obj = Knearest(data.train_x[:10000], data.train_y[:10000], samples)\n",
    "    yout = np.zeros(len(data.test_x),  dtype=int)\n",
    "    for i in range(len(data.test_x)):\n",
    "        yout[i] = obj.classify(data.test_x[i])\n",
    "\n",
    "    C = obj.confusion_matrix(yout,data.test_y)\n",
    "    acc = Knearest.accuracy(C)\n",
    "    accs.append(acc)\n",
    "plot_data = {}\n",
    "for i in range(len(k_samples)):\n",
    "    plot_data[k_samples[i]] = accs[i]\n",
    "\n",
    "plt.bar(np.arange(len(plot_data)), plot_data.values(), align=\"center\", width=0.2, color='g')\n",
    "plt.xticks(range(len(plot_data)), list(plot_data.keys()))\n",
    "plt.xlabel(\"k values\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Which numbers get confused with each other the most easily?  Use the confusion_matrix function that you wrote above to support your conclusion.  Then use the `view_digit` function given below to plot a few examples of misclassified digits and discuss possible reasons for the misclassifications.  (Investigating misclassified examples is called **error analysis** and is an important step in the development of any classification technique).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4bda21080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def view_digit(example, label=None):\n",
    "    if label: print(\"true label: {:d}\".format(label))\n",
    "    plt.imshow(example.reshape(28,28), cmap='gray');\n",
    "    \n",
    "view_digit(data.train_x[0,:], data.train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The confusion matrix obtained for k=5 and 10000 training samples is shown below:\n",
    "\n",
    "[[ 979    0    3    1    0    5    4    0    8    7]\n",
    " [   1 1060   17    1   18    8    1   17   27    6]\n",
    " [   2    3  926    3    0    1    0    2    3    1]\n",
    " [   0    0    8  998    0   26    0    0   26   11]\n",
    " [   1    0    0    0  908    5    0    3    3   15]\n",
    " [   1    0    0    5    0  833    2    0   11    3]\n",
    " [   3    0    4    0    2   22  959    0    6    0]\n",
    " [   3    1   27    7    5    2    0 1059    8   23]\n",
    " [   1    0    2    9    0    5    1    0  894    0]\n",
    " [   0    0    3    6   50    8    0    9   23  895]]\n",
    " \n",
    " As we can see , 50 number of times 9 is classified as 4, 27 times 7  is classified as 3 and 27 times 1 is classified as 8, 23 times 9 is classified as 8. \n",
    "Using the below view_digit function, the reason behind several mismatch are due to the identical strokes between the two digits. \n",
    "For example the value 3 and 9 have very common strokes. The same goes with 4,9 and 7,1. There were several 8's which were predicted as 1, this is due to the fact that the training examples have certain 8s which are very thin and visually look like thick 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted val: 3\n",
      "true label: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkeSjBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4c0322940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj = Knearest(data.train_x[:1000], data.train_y[:1000],5)\n",
    "yout = np.zeros(len(data.test_x),  dtype=int)\n",
    "count =2\n",
    "for i in range(len(data.test_x)):\n",
    "    yout[i] = obj.classify(data.test_x[i])\n",
    "    if data.test_y[i] == 9:\n",
    "        if (yout[i] != data.test_y[i]):\n",
    "            print(\"Predicted val:\", yout[i])\n",
    "            view_digit(data.test_x[i,:], data.test_y[i])\n",
    "            break;\n",
    "for i in range(len(data.test_x)):\n",
    "    yout[i] = obj.classify(data.test_x[i])\n",
    "    if data.test_y[i] == 7:\n",
    "        if (yout[i] != data.test_y[i]):\n",
    "            print(\"Predicted val:\", yout[i])\n",
    "            view_digit(data.test_x[i,:], data.test_y[i])\n",
    "            break;\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
